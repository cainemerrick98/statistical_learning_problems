{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Selection and Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, statsmodels.api as sm\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Forward and backward stepwise regression with simulated data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(a) Create a random number generator and use its `normal()` method to generate a predictor X of length $n = 100$, as well as a noise vector $\\epsilon$ of length $n = 100$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randn(100)\n",
    "e = np.random.randn(100)\n",
    "\n",
    "X.shape, e.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(b) Generate a response vector $Y$ of length $n = 100$ according to the model*\n",
    "\n",
    "$$\n",
    "Y = \\beta_{0} +\\beta_{1}X + \\beta_{2}X^{2} + \\beta_{3}X_{3} + \\epsilon\n",
    "$$\n",
    "\n",
    "Where $\\beta_{0} +\\beta_{1} + \\beta_{2} + \\beta_{3}$ are constants of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 + 7*X - 2*X**2 + 1/2 * X**3 + e\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(c) Use forward stepwise selection in order to select a model containing the predictors $X,X_{2}, . . . ,X_{10}$. What is the model obtained according to $C_{p}$? Report the coefficients of the model obtained.*\n",
    "\n",
    "Firstly, $C_{p}$ is not a metric in sklearn or statsmodel, so we will write a function to calculate this. For a fitted least squares model with $d$ predictors, the $C_{p}$ estimate of the test MSE is computed by,\n",
    "\n",
    "$$\n",
    "C_{p} = \\frac{1}{n}(RSS + 2d\\hat{\\sigma}^{2})\n",
    "$$\n",
    "\n",
    "Where $\\hat{\\sigma}^{2}$ is an estimate of the variance of the error $\\epsilon$ associated with each response measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCp(sigma2:float, estimator:BaseEstimator, X:np.ndarray, y:np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    negative Cp statistic\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    yhat = estimator.predict(X)\n",
    "    rss = np.sum((y - yhat)**2)\n",
    "    return -(rss + 2 * p * sigma2)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also no built in functionality for performing stepwise regression in sklearn. We will write a function to perform forward stepwise selection to select a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_regression(X:np.ndarray, y:np.ndarray, scoring_func:callable):\n",
    "    \"\"\"\n",
    "    Performs forward stepwise regression based on the scoring function passed.\n",
    "    Forward stepwise regression starts with the null model and sequentially adds\n",
    "    predictors, selecting only the best performing model with at each stage.\n",
    "    Performance is defined by the return value of the scoring_func argument passed to the model.\n",
    "    Forward stepwise seeks to maximise the scoring function.\n",
    "\n",
    "    The function returns the an array containing the column indexes of the best predictors\n",
    "    \"\"\"\n",
    "    best_score = -float('inf')\n",
    "    best_predictors = []\n",
    "    continue_search = True\n",
    "\n",
    "    while continue_search:\n",
    "        predictor_used = None\n",
    "        for p in range(X.shape[1]):\n",
    "            if p not in best_predictors:\n",
    "                X_current = sm.add_constant(X[:, best_predictors + [p]])\n",
    "                model = sm.OLS(y, X_current).fit()\n",
    "                score = scoring_func(model, X_current, y)\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    predictor_used = p\n",
    "        \n",
    "        if predictor_used is None:\n",
    "            continue_search = False\n",
    "        else:\n",
    "            best_predictors.append(predictor_used)\n",
    "\n",
    "    \n",
    "    return best_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\sigma^{2}$ used to calculate the $C_{p}$ statistic is usually estimated using the full model containing all of the predictors. Lets calculate this and freeze its value in a new partial object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first lets create the full set of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full = np.power.outer(X, range(1, 11))\n",
    "X_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   857.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Jul 2024</td> <th>  Prob (F-statistic):</th> <td>6.53e-84</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:52:16</td>     <th>  Log-Likelihood:    </th> <td> -137.20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   296.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    89</td>      <th>  BIC:               </th> <td>   325.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.1051</td> <td>    0.218</td> <td>    9.637</td> <td> 0.000</td> <td>    1.671</td> <td>    2.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    7.6781</td> <td>    0.550</td> <td>   13.966</td> <td> 0.000</td> <td>    6.586</td> <td>    8.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.6542</td> <td>    1.306</td> <td>   -1.266</td> <td> 0.209</td> <td>   -4.250</td> <td>    0.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1036</td> <td>    1.238</td> <td>   -0.084</td> <td> 0.934</td> <td>   -2.564</td> <td>    2.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.6888</td> <td>    1.926</td> <td>   -0.358</td> <td> 0.721</td> <td>   -4.516</td> <td>    3.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0491</td> <td>    0.797</td> <td>    0.062</td> <td> 0.951</td> <td>   -1.534</td> <td>    1.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.4023</td> <td>    0.987</td> <td>    0.408</td> <td> 0.684</td> <td>   -1.558</td> <td>    2.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0050</td> <td>    0.183</td> <td>    0.027</td> <td> 0.978</td> <td>   -0.358</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0753</td> <td>    0.187</td> <td>   -0.403</td> <td> 0.688</td> <td>   -0.446</td> <td>    0.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 8.715e-05</td> <td>    0.015</td> <td>    0.006</td> <td> 0.995</td> <td>   -0.029</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0042</td> <td>    0.011</td> <td>    0.371</td> <td> 0.712</td> <td>   -0.018</td> <td>    0.027</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.152</td> <th>  Durbin-Watson:     </th> <td>   1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.927</td> <th>  Jarque-Bera (JB):  </th> <td>   0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.026</td> <th>  Prob(JB):          </th> <td>   0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.024</td> <th>  Cond. No.          </th> <td>3.42e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.42e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.990   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.989   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     857.2   \\\\\n",
       "\\textbf{Date:}             & Fri, 12 Jul 2024 & \\textbf{  Prob (F-statistic):} &  6.53e-84   \\\\\n",
       "\\textbf{Time:}             &     14:52:16     & \\textbf{  Log-Likelihood:    } &   -137.20   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     296.4   \\\\\n",
       "\\textbf{Df Residuals:}     &          89      & \\textbf{  BIC:               } &     325.1   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       2.1051  &        0.218     &     9.637  &         0.000        &        1.671    &        2.539     \\\\\n",
       "\\textbf{x1}    &       7.6781  &        0.550     &    13.966  &         0.000        &        6.586    &        8.770     \\\\\n",
       "\\textbf{x2}    &      -1.6542  &        1.306     &    -1.266  &         0.209        &       -4.250    &        0.942     \\\\\n",
       "\\textbf{x3}    &      -0.1036  &        1.238     &    -0.084  &         0.934        &       -2.564    &        2.357     \\\\\n",
       "\\textbf{x4}    &      -0.6888  &        1.926     &    -0.358  &         0.721        &       -4.516    &        3.138     \\\\\n",
       "\\textbf{x5}    &       0.0491  &        0.797     &     0.062  &         0.951        &       -1.534    &        1.632     \\\\\n",
       "\\textbf{x6}    &       0.4023  &        0.987     &     0.408  &         0.684        &       -1.558    &        2.363     \\\\\n",
       "\\textbf{x7}    &       0.0050  &        0.183     &     0.027  &         0.978        &       -0.358    &        0.368     \\\\\n",
       "\\textbf{x8}    &      -0.0753  &        0.187     &    -0.403  &         0.688        &       -0.446    &        0.296     \\\\\n",
       "\\textbf{x9}    &    8.715e-05  &        0.015     &     0.006  &         0.995        &       -0.029    &        0.029     \\\\\n",
       "\\textbf{x10}   &       0.0042  &        0.011     &     0.371  &         0.712        &       -0.018    &        0.027     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.152 & \\textbf{  Durbin-Watson:     } &    1.972  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.927 & \\textbf{  Jarque-Bera (JB):  } &    0.014  \\\\\n",
       "\\textbf{Skew:}          &  0.026 & \\textbf{  Prob(JB):          } &    0.993  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.024 & \\textbf{  Cond. No.          } & 3.42e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 3.42e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.990\n",
       "Model:                            OLS   Adj. R-squared:                  0.989\n",
       "Method:                 Least Squares   F-statistic:                     857.2\n",
       "Date:                Fri, 12 Jul 2024   Prob (F-statistic):           6.53e-84\n",
       "Time:                        14:52:16   Log-Likelihood:                -137.20\n",
       "No. Observations:                 100   AIC:                             296.4\n",
       "Df Residuals:                      89   BIC:                             325.1\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.1051      0.218      9.637      0.000       1.671       2.539\n",
       "x1             7.6781      0.550     13.966      0.000       6.586       8.770\n",
       "x2            -1.6542      1.306     -1.266      0.209      -4.250       0.942\n",
       "x3            -0.1036      1.238     -0.084      0.934      -2.564       2.357\n",
       "x4            -0.6888      1.926     -0.358      0.721      -4.516       3.138\n",
       "x5             0.0491      0.797      0.062      0.951      -1.534       1.632\n",
       "x6             0.4023      0.987      0.408      0.684      -1.558       2.363\n",
       "x7             0.0050      0.183      0.027      0.978      -0.358       0.368\n",
       "x8            -0.0753      0.187     -0.403      0.688      -0.446       0.296\n",
       "x9          8.715e-05      0.015      0.006      0.995      -0.029       0.029\n",
       "x10            0.0042      0.011      0.371      0.712      -0.018       0.027\n",
       "==============================================================================\n",
       "Omnibus:                        0.152   Durbin-Watson:                   1.972\n",
       "Prob(Omnibus):                  0.927   Jarque-Bera (JB):                0.014\n",
       "Skew:                           0.026   Prob(JB):                        0.993\n",
       "Kurtosis:                       3.024   Cond. No.                     3.42e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.42e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full_wconstant = sm.add_constant(X_full)\n",
    "full_model = sm.OLS(y, X_full_wconstant).fit()\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale property of the full model is the estimate $\\sigma^{2}$. Now we create this variable and use it to freeze the Cp function and create a partial object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0229993650661822\n"
     ]
    }
   ],
   "source": [
    "sigma2 = full_model.scale\n",
    "print(sigma2)\n",
    "nCp_frozen = partial(nCp, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This partial object can now be used as the scoring function in our forward stepwise regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 1, 4]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsr_predictors = forward_stepwise_regression(X_full, y, nCp_frozen)\n",
    "fsr_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward stepwise regression selected the following predictors $X, X^{4}, X^{2}, X^{5}$ The coefficients are reported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2229.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Jul 2024</td> <th>  Prob (F-statistic):</th> <td>5.89e-93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:01:15</td>     <th>  Log-Likelihood:    </th> <td> -138.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   287.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    95</td>      <th>  BIC:               </th> <td>   300.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Const</th> <td>    2.1443</td> <td>    0.145</td> <td>   14.791</td> <td> 0.000</td> <td>    1.856</td> <td>    2.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>     <td>    7.6372</td> <td>    0.130</td> <td>   58.724</td> <td> 0.000</td> <td>    7.379</td> <td>    7.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>    <td>    0.0292</td> <td>    0.032</td> <td>    0.901</td> <td> 0.370</td> <td>   -0.035</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>   -2.0395</td> <td>    0.196</td> <td>  -10.395</td> <td> 0.000</td> <td>   -2.429</td> <td>   -1.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>    <td>    0.0531</td> <td>    0.006</td> <td>    8.813</td> <td> 0.000</td> <td>    0.041</td> <td>    0.065</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.008</td> <th>  Durbin-Watson:     </th> <td>   1.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.996</td> <th>  Jarque-Bera (JB):  </th> <td>   0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.016</td> <th>  Prob(JB):          </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.840</td> <th>  Cond. No.          </th> <td>    92.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.989   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.989   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2229.   \\\\\n",
       "\\textbf{Date:}             & Fri, 12 Jul 2024 & \\textbf{  Prob (F-statistic):} &  5.89e-93   \\\\\n",
       "\\textbf{Time:}             &     15:01:15     & \\textbf{  Log-Likelihood:    } &   -138.49   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     287.0   \\\\\n",
       "\\textbf{Df Residuals:}     &          95      & \\textbf{  BIC:               } &     300.0   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Const} &       2.1443  &        0.145     &    14.791  &         0.000        &        1.856    &        2.432     \\\\\n",
       "\\textbf{X}     &       7.6372  &        0.130     &    58.724  &         0.000        &        7.379    &        7.895     \\\\\n",
       "\\textbf{X4}    &       0.0292  &        0.032     &     0.901  &         0.370        &       -0.035    &        0.093     \\\\\n",
       "\\textbf{X2}    &      -2.0395  &        0.196     &   -10.395  &         0.000        &       -2.429    &       -1.650     \\\\\n",
       "\\textbf{X5}    &       0.0531  &        0.006     &     8.813  &         0.000        &        0.041    &        0.065     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.008 & \\textbf{  Durbin-Watson:     } &    1.974  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.996 & \\textbf{  Jarque-Bera (JB):  } &    0.111  \\\\\n",
       "\\textbf{Skew:}          &  0.016 & \\textbf{  Prob(JB):          } &    0.946  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.840 & \\textbf{  Cond. No.          } &     92.0  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.989\n",
       "Model:                            OLS   Adj. R-squared:                  0.989\n",
       "Method:                 Least Squares   F-statistic:                     2229.\n",
       "Date:                Fri, 12 Jul 2024   Prob (F-statistic):           5.89e-93\n",
       "Time:                        15:01:15   Log-Likelihood:                -138.49\n",
       "No. Observations:                 100   AIC:                             287.0\n",
       "Df Residuals:                      95   BIC:                             300.0\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Const          2.1443      0.145     14.791      0.000       1.856       2.432\n",
       "X              7.6372      0.130     58.724      0.000       7.379       7.895\n",
       "X4             0.0292      0.032      0.901      0.370      -0.035       0.093\n",
       "X2            -2.0395      0.196    -10.395      0.000      -2.429      -1.650\n",
       "X5             0.0531      0.006      8.813      0.000       0.041       0.065\n",
       "==============================================================================\n",
       "Omnibus:                        0.008   Durbin-Watson:                   1.974\n",
       "Prob(Omnibus):                  0.996   Jarque-Bera (JB):                0.111\n",
       "Skew:                           0.016   Prob(JB):                        0.946\n",
       "Kurtosis:                       2.840   Cond. No.                         92.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_predictors_df = pd.DataFrame(data=sm.add_constant(X_full[:, fsr_predictors]), columns=['Const', 'X', 'X4', 'X2', 'X5'])\n",
    "fsr_model = sm.OLS(y, selected_predictors_df).fit()\n",
    "fsr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(d) Now do the same but use backward stepwise regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again there is no implementation of backward stepwise regression so we will write a function to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_stepwise_regression(X:np.ndarray, y:np.ndarray, scoring_func:callable):\n",
    "    \"\"\"\n",
    "    Performs backward stepwise regression based on the scoring function passed.\n",
    "    Backward stepwise regression starts with the full model and sequentially removes\n",
    "    predictors, selecting only the best performing model with at each stage.\n",
    "    Performance is defined by the return value of the scoring_func argument passed to the model.\n",
    "    Backward stepwise seeks to maximise the scoring function.\n",
    "\n",
    "    The function returns the an array containing the column indexes of the best predictors\n",
    "    \"\"\"\n",
    "    full_model = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "    best_score = scoring_func(full_model, sm.add_constant(X), y)\n",
    "    best_predictors = [i for i in range(X.shape[1])]\n",
    "    continue_search = True\n",
    "    \n",
    "    while continue_search:\n",
    "        predictor_removed = None\n",
    "        for p in range(X.shape[1]):\n",
    "            if p in best_predictors:\n",
    "                X_currrent = sm.add_constant(X[:, [i for i in best_predictors if i != p]])\n",
    "                model = sm.OLS(y, X_currrent).fit()\n",
    "                score = scoring_func(model, X_currrent, y)\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    predictor_removed = p\n",
    "        \n",
    "        if predictor_removed is None:\n",
    "            continue_search = False\n",
    "\n",
    "        else:\n",
    "            best_predictors.remove(predictor_removed)\n",
    "    \n",
    "    return best_predictors\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run backward stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 5, 6, 7, 9]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsr_predictors = backward_stepwise_regression(X_full, y, nCp_frozen)\n",
    "bsr_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1483.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 13 Jul 2024</td> <th>  Prob (F-statistic):</th> <td>5.38e-90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:58:14</td>     <th>  Log-Likelihood:    </th> <td> -137.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   289.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    93</td>      <th>  BIC:               </th> <td>   307.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Const</th> <td>    2.1896</td> <td>    0.161</td> <td>   13.604</td> <td> 0.000</td> <td>    1.870</td> <td>    2.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>     <td>    7.6282</td> <td>    0.139</td> <td>   55.027</td> <td> 0.000</td> <td>    7.353</td> <td>    7.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>   -2.2557</td> <td>    0.297</td> <td>   -7.604</td> <td> 0.000</td> <td>   -2.845</td> <td>   -1.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X6</th>    <td>    0.1497</td> <td>    0.087</td> <td>    1.719</td> <td> 0.089</td> <td>   -0.023</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X7</th>    <td>    0.0109</td> <td>    0.002</td> <td>    6.320</td> <td> 0.000</td> <td>    0.007</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X8</th>    <td>   -0.0402</td> <td>    0.021</td> <td>   -1.876</td> <td> 0.064</td> <td>   -0.083</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X10</th>   <td>    0.0027</td> <td>    0.001</td> <td>    2.061</td> <td> 0.042</td> <td> 9.81e-05</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.025</td> <th>  Durbin-Watson:     </th> <td>   1.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.988</td> <th>  Jarque-Bera (JB):  </th> <td>   0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.020</td> <th>  Prob(JB):          </th> <td>   0.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.917</td> <th>  Cond. No.          </th> <td>4.42e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.42e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.990   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.989   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     1483.   \\\\\n",
       "\\textbf{Date:}             & Sat, 13 Jul 2024 & \\textbf{  Prob (F-statistic):} &  5.38e-90   \\\\\n",
       "\\textbf{Time:}             &     08:58:14     & \\textbf{  Log-Likelihood:    } &   -137.52   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     289.0   \\\\\n",
       "\\textbf{Df Residuals:}     &          93      & \\textbf{  BIC:               } &     307.3   \\\\\n",
       "\\textbf{Df Model:}         &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Const} &       2.1896  &        0.161     &    13.604  &         0.000        &        1.870    &        2.509     \\\\\n",
       "\\textbf{X}     &       7.6282  &        0.139     &    55.027  &         0.000        &        7.353    &        7.903     \\\\\n",
       "\\textbf{X2}    &      -2.2557  &        0.297     &    -7.604  &         0.000        &       -2.845    &       -1.667     \\\\\n",
       "\\textbf{X6}    &       0.1497  &        0.087     &     1.719  &         0.089        &       -0.023    &        0.323     \\\\\n",
       "\\textbf{X7}    &       0.0109  &        0.002     &     6.320  &         0.000        &        0.007    &        0.014     \\\\\n",
       "\\textbf{X8}    &      -0.0402  &        0.021     &    -1.876  &         0.064        &       -0.083    &        0.002     \\\\\n",
       "\\textbf{X10}   &       0.0027  &        0.001     &     2.061  &         0.042        &     9.81e-05    &        0.005     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.025 & \\textbf{  Durbin-Watson:     } &    1.947  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.988 & \\textbf{  Jarque-Bera (JB):  } &    0.036  \\\\\n",
       "\\textbf{Skew:}          & -0.020 & \\textbf{  Prob(JB):          } &    0.982  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.917 & \\textbf{  Cond. No.          } & 4.42e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 4.42e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.990\n",
       "Model:                            OLS   Adj. R-squared:                  0.989\n",
       "Method:                 Least Squares   F-statistic:                     1483.\n",
       "Date:                Sat, 13 Jul 2024   Prob (F-statistic):           5.38e-90\n",
       "Time:                        08:58:14   Log-Likelihood:                -137.52\n",
       "No. Observations:                 100   AIC:                             289.0\n",
       "Df Residuals:                      93   BIC:                             307.3\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Const          2.1896      0.161     13.604      0.000       1.870       2.509\n",
       "X              7.6282      0.139     55.027      0.000       7.353       7.903\n",
       "X2            -2.2557      0.297     -7.604      0.000      -2.845      -1.667\n",
       "X6             0.1497      0.087      1.719      0.089      -0.023       0.323\n",
       "X7             0.0109      0.002      6.320      0.000       0.007       0.014\n",
       "X8            -0.0402      0.021     -1.876      0.064      -0.083       0.002\n",
       "X10            0.0027      0.001      2.061      0.042    9.81e-05       0.005\n",
       "==============================================================================\n",
       "Omnibus:                        0.025   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.988   Jarque-Bera (JB):                0.036\n",
       "Skew:                          -0.020   Prob(JB):                        0.982\n",
       "Kurtosis:                       2.917   Cond. No.                     4.42e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.42e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsr_selected_predictors = pd.DataFrame(data=sm.add_constant(X_full[:, bsr_predictors]), columns=['Const', 'X', 'X2', 'X6', 'X7', 'X8', 'X10'])\n",
    "bsr_model = sm.OLS(y, bsr_selected_predictors).fit()\n",
    "bsr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(e) Now fit a lasso model agaisnt the simulated data. Use cross-validation to select the optimal $\\lambda$. Create plots of the cross-validation error as a function of $\\lambda$. Report the coefficient estimates and discuss the results obtained.*\n",
    "\n",
    "We can fit a lasso model with cross validation using the `sklearn.ElasticNetCV()` function. Furthermore, it is important to standardise the predictors when fitting a lasso model. To scale the predictors we can use the `StandardScaler()` object provided by sklearn. Finally, we can package up feature preprocessing and model fitting into a single object by using sklearns `Pipeline()` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;lasso&#x27;,\n",
       "                 ElasticNetCV(alphas=array([1.06234557e+07, 8.41890700e+06, 6.67183982e+06, 5.28731896e+06,\n",
       "       4.19010985e+06, 3.32059040e+06, 2.63151110e+06, 2.08542755e+06,\n",
       "       1.65266567e+06, 1.30970928e+06, 1.03792220e+06, 8.22535597e+05,\n",
       "       6.51845394e+05, 5.16576327e+05, 4.09377905e+05, 3.24424988e+05,\n",
       "       2.57101255e+05, 2.03748348e+05,...\n",
       "       2.23613560e-01, 1.77209922e-01, 1.40435833e-01, 1.11292996e-01,\n",
       "       8.81977959e-02, 6.98952449e-02, 5.53907863e-02, 4.38962509e-02,\n",
       "       3.47870281e-02, 2.75681249e-02, 2.18472675e-02, 1.73135859e-02,\n",
       "       1.37207207e-02, 1.08734365e-02, 8.61701248e-03, 6.82883503e-03,\n",
       "       5.41173497e-03, 4.28870742e-03, 3.39872728e-03, 2.69343325e-03,\n",
       "       2.13449979e-03, 1.69155458e-03, 1.34052808e-03, 1.06234557e-03]),\n",
       "                              cv=5, l1_ratio=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;lasso&#x27;,\n",
       "                 ElasticNetCV(alphas=array([1.06234557e+07, 8.41890700e+06, 6.67183982e+06, 5.28731896e+06,\n",
       "       4.19010985e+06, 3.32059040e+06, 2.63151110e+06, 2.08542755e+06,\n",
       "       1.65266567e+06, 1.30970928e+06, 1.03792220e+06, 8.22535597e+05,\n",
       "       6.51845394e+05, 5.16576327e+05, 4.09377905e+05, 3.24424988e+05,\n",
       "       2.57101255e+05, 2.03748348e+05,...\n",
       "       2.23613560e-01, 1.77209922e-01, 1.40435833e-01, 1.11292996e-01,\n",
       "       8.81977959e-02, 6.98952449e-02, 5.53907863e-02, 4.38962509e-02,\n",
       "       3.47870281e-02, 2.75681249e-02, 2.18472675e-02, 1.73135859e-02,\n",
       "       1.37207207e-02, 1.08734365e-02, 8.61701248e-03, 6.82883503e-03,\n",
       "       5.41173497e-03, 4.28870742e-03, 3.39872728e-03, 2.69343325e-03,\n",
       "       2.13449979e-03, 1.69155458e-03, 1.34052808e-03, 1.06234557e-03]),\n",
       "                              cv=5, l1_ratio=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;ElasticNetCV<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.ElasticNetCV.html\">?<span>Documentation for ElasticNetCV</span></a></label><div class=\"sk-toggleable__content \"><pre>ElasticNetCV(alphas=array([1.06234557e+07, 8.41890700e+06, 6.67183982e+06, 5.28731896e+06,\n",
       "       4.19010985e+06, 3.32059040e+06, 2.63151110e+06, 2.08542755e+06,\n",
       "       1.65266567e+06, 1.30970928e+06, 1.03792220e+06, 8.22535597e+05,\n",
       "       6.51845394e+05, 5.16576327e+05, 4.09377905e+05, 3.24424988e+05,\n",
       "       2.57101255e+05, 2.03748348e+05, 1.61467081e+05, 1.27959901e+05,\n",
       "       1.01406033e+05, 8.036254...\n",
       "       2.23613560e-01, 1.77209922e-01, 1.40435833e-01, 1.11292996e-01,\n",
       "       8.81977959e-02, 6.98952449e-02, 5.53907863e-02, 4.38962509e-02,\n",
       "       3.47870281e-02, 2.75681249e-02, 2.18472675e-02, 1.73135859e-02,\n",
       "       1.37207207e-02, 1.08734365e-02, 8.61701248e-03, 6.82883503e-03,\n",
       "       5.41173497e-03, 4.28870742e-03, 3.39872728e-03, 2.69343325e-03,\n",
       "       2.13449979e-03, 1.69155458e-03, 1.34052808e-03, 1.06234557e-03]),\n",
       "             cv=5, l1_ratio=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lasso',\n",
       "                 ElasticNetCV(alphas=array([1.06234557e+07, 8.41890700e+06, 6.67183982e+06, 5.28731896e+06,\n",
       "       4.19010985e+06, 3.32059040e+06, 2.63151110e+06, 2.08542755e+06,\n",
       "       1.65266567e+06, 1.30970928e+06, 1.03792220e+06, 8.22535597e+05,\n",
       "       6.51845394e+05, 5.16576327e+05, 4.09377905e+05, 3.24424988e+05,\n",
       "       2.57101255e+05, 2.03748348e+05,...\n",
       "       2.23613560e-01, 1.77209922e-01, 1.40435833e-01, 1.11292996e-01,\n",
       "       8.81977959e-02, 6.98952449e-02, 5.53907863e-02, 4.38962509e-02,\n",
       "       3.47870281e-02, 2.75681249e-02, 2.18472675e-02, 1.73135859e-02,\n",
       "       1.37207207e-02, 1.08734365e-02, 8.61701248e-03, 6.82883503e-03,\n",
       "       5.41173497e-03, 4.28870742e-03, 3.39872728e-03, 2.69343325e-03,\n",
       "       2.13449979e-03, 1.69155458e-03, 1.34052808e-03, 1.06234557e-03]),\n",
       "                              cv=5, l1_ratio=1))])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "lambdas = 10**np.linspace(8, -2, 100) / y.std()\n",
    "lasso_cv = skl.ElasticNetCV(alphas=lambdas, l1_ratio=1, cv=5)\n",
    "pipeline = Pipeline(steps=[('scaler', scaler), ('lasso', lasso_cv)])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caine\\OneDrive\\Documents\\statistical_learning_problems\\sl_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9413994376839412, tolerance: 0.719078687713134\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\caine\\OneDrive\\Documents\\statistical_learning_problems\\sl_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6338278297445896, tolerance: 0.719078687713134\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\caine\\OneDrive\\Documents\\statistical_learning_problems\\sl_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.25256268059114, tolerance: 0.7652816610686924\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\caine\\OneDrive\\Documents\\statistical_learning_problems\\sl_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7168298828716217, tolerance: 0.7652816610686924\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(sm.add_constant(X_full), y)\n",
    "tuned_lasso = pipeline.named_steps['lasso']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the cv error as a function of the $-log(\\lambda)$ which has shrinkage decreasing from left to right. We can see the optimal value of $\\lambda$ plotted on the chart. Also note that for a large range of $\\lambda$ values the same model is fit - this is the straight horizontal line on the chart. Here the shrinkage parameter is too large which results in the null model always being fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$-log(\\\\lambda)$')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "ax.plot(-np.log(tuned_lasso.alphas_), tuned_lasso.mse_path_.mean(1))\n",
    "ax.axvline(-np.log(tuned_lasso.alpha_), c='k', ls='--')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_xlabel(r'$-log(\\lambda)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the coefficient estimates of the lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Const    0.000000\n",
       "X        7.118676\n",
       "X2      -2.840373\n",
       "X3       0.790322\n",
       "X4      -0.000000\n",
       "X5       1.207820\n",
       "X6      -0.000000\n",
       "X7       0.000000\n",
       "X8      -0.000000\n",
       "X9       0.000000\n",
       "X10     -0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coefs = pd.Series(data=tuned_lasso.coef_.T, index=['Const', 'X', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10'])\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many of the coefficient estimates have been shrunk to 0. Furthermore, the lasso has correctly identified all of the predictors that have a relationship with response (except the intercept), it has incorrectly identified $X_{5}$ as being a significant predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(f) Now generate a response vector $Y$ according to the model*\n",
    "\n",
    "$$\n",
    "Y = \\beta_{0} + \\beta_{7}X^{7} + \\epsilon\n",
    "$$\n",
    "\n",
    "Perform forward stepwise selection and the lasso. Discuss the results obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 5 + 2*X**7 + e\n",
    "\n",
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
